import * as snarkjs from 'snarkjs';
import path from 'path';
import { fileURLToPath } from 'url';
import fs from 'fs';
import crypto from 'crypto';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * ZK Proof Generator - Dual Proof System
 *
 * Generates dual proofs for partial transparency:
 * 1. Main proof (full dataset, 95% private + 5% public)
 * 2. Subset proof (5% public tests, fully transparent)
 *
 * Enhanced with commitments to:
 * - Execution logs (proves logs exist and can't be changed)
 * - Library version (proves specific library was used)
 * - Scoring method (proves evaluation criteria)
 *
 * The two proofs are cryptographically linked via the subset verification
 * constraints in the main circuit.
 */
export class ProofGenerator {
  constructor(config = {}) {
    const projectRoot = path.join(__dirname, '../..');

    // Main circuit paths (full dataset)
    this.wasmPath = config.wasmPath ||
      path.join(projectRoot, 'circuits/verifier_js/verifier.wasm');

    this.zkeyPath = config.zkeyPath ||
      path.join(projectRoot, 'circuits/verifier_final.zkey');

    this.vkeyPath = config.vkeyPath ||
      path.join(projectRoot, 'circuits/verification_key.json');

    // Subset circuit paths (public 5%)
    this.wasmPathSubset = config.wasmPathSubset ||
      path.join(projectRoot, 'circuits/verifier-subset_js/verifier-subset.wasm');

    this.zkeyPathSubset = config.zkeyPathSubset ||
      path.join(projectRoot, 'circuits/verifier-subset_final.zkey');

    this.vkeyPathSubset = config.vkeyPathSubset ||
      path.join(projectRoot, 'circuits/verification_key_subset.json');

    // Default to 100 to match compiled circuit (can handle up to 100 tests)
    this.maxTests = config.maxTests || 100;
    this.maxSubset = config.maxSubset || 10;
    this.libraryVersion = config.libraryVersion || '1.0.0';
  }

  /**
   * Generate enhanced proof with commitments
   */
  async generateProof({
    testResults,
    merkleRoot,
    aggregateScore,
    numTests,
    executionLogs,      // NEW: execution logs
    scoringCriteria     // NEW: scoring method
  }) {
    const setup = this.checkSetup();

    if (!setup.wasmExists || !setup.zkeyExists || !setup.vkeyExists) {
      console.log('⚠️  Enhanced circuit not compiled, using standard proof');
      return this.generatePlaceholderProof({
        merkleRoot,
        aggregateScore,
        numTests,
        executionLogs,
        scoringCriteria
      });
    }

    try {
      // Prepare enhanced circuit inputs
      const circuitInputs = this.prepareEnhancedCircuitInputs({
        testResults,
        merkleRoot,
        aggregateScore,
        numTests,
        executionLogs,
        scoringCriteria
      });

      // Generate witness and proof
      const { proof, publicSignals } = await snarkjs.groth16.fullProve(
        circuitInputs,
        this.wasmPath,
        this.zkeyPath
      );

      // Load verification key
      const vKey = JSON.parse(
        await fs.promises.readFile(this.vkeyPath, 'utf8')
      );

      return {
        proof,
        publicSignals,
        verificationKey: vKey,
        protocol: 'groth16',
        curve: 'bn128',
        isPlaceholder: false,
        // Enhanced: include public commitments
        commitments: {
          logsCommitment: circuitInputs.logsHash.toString(),
          libraryVersion: circuitInputs.libraryCodeHash.toString(),
          scoringMethod: circuitInputs.scoringMethodHash.toString()
        }
      };

    } catch (error) {
      console.error('❌ Enhanced proof generation failed:', error.message);
      console.warn('   Falling back to placeholder proof');

      return this.generatePlaceholderProof({
        merkleRoot,
        aggregateScore,
        numTests,
        executionLogs,
        scoringCriteria
      });
    }
  }

  /**
   * Generate dual proofs (main + subset) for partial transparency
   */
  async generateDualProof({
    testResults,          // All test results
    merkleRoot,           // Full dataset Merkle root
    aggregateScore,       // Full dataset aggregate score
    numTests,             // Total number of tests
    executionLogs,        // Execution logs
    scoringCriteria,      // Scoring method
    publicIndices,        // Which tests are public (5%)
    publicResults,        // Results for public tests
    subsetMerkleRoot,     // Merkle root for public subset
    subsetAggregateScore  // Aggregate score for public subset
  }) {
    const setup = this.checkSetup();
    const subsetSetup = this.checkSubsetSetup();

    // If either circuit is not compiled, fall back to placeholder
    if (!setup.wasmExists || !setup.zkeyExists || !setup.vkeyExists ||
        !subsetSetup.wasmExists || !subsetSetup.zkeyExists || !subsetSetup.vkeyExists) {
      console.log('⚠️  Circuits not compiled, using placeholder dual proof');
      return this.generatePlaceholderDualProof({
        merkleRoot,
        aggregateScore,
        numTests,
        executionLogs,
        scoringCriteria,
        publicIndices,
        subsetMerkleRoot,
        subsetAggregateScore,
        publicResults
      });
    }

    try {
      // Generate subset proof first (public 5%)
      console.log('  Generating subset proof (public 5%)...');
      const subsetProof = await this.generateSubsetProof({
        publicResults,
        subsetMerkleRoot,
        subsetAggregateScore,
        numSubset: publicResults.length
      });

      // Generate main proof (full dataset, with subset verification)
      console.log('  Generating main proof (full dataset)...');
      const mainProof = await this.generateMainProof({
        testResults,
        merkleRoot,
        aggregateScore,
        numTests,
        executionLogs,
        scoringCriteria,
        publicIndices,
        publicResults,
        subsetMerkleRoot,
        subsetAggregateScore
      });

      return {
        mainProof,
        subsetProof,
        isPlaceholder: false,
        protocol: 'groth16-dual',
        publicIndices,
        publicTests: publicResults.length
      };

    } catch (error) {
      console.error('❌ Dual proof generation failed:', error.message);
      console.warn('   Falling back to placeholder dual proof');

      return this.generatePlaceholderDualProof({
        merkleRoot,
        aggregateScore,
        numTests,
        executionLogs,
        scoringCriteria,
        publicIndices,
        subsetMerkleRoot,
        subsetAggregateScore,
        publicResults
      });
    }
  }

  /**
   * Generate subset proof (public 5% tests)
   */
  async generateSubsetProof({
    publicResults,
    subsetMerkleRoot,
    subsetAggregateScore,
    numSubset
  }) {
    const circuitInputs = this.prepareSubsetCircuitInputs({
      publicResults,
      subsetMerkleRoot,
      subsetAggregateScore,
      numSubset
    });

    // Generate witness and proof for subset circuit
    const { proof, publicSignals } = await snarkjs.groth16.fullProve(
      circuitInputs,
      this.wasmPathSubset,
      this.zkeyPathSubset
    );

    // Load verification key
    const vKey = JSON.parse(
      await fs.promises.readFile(this.vkeyPathSubset, 'utf8')
    );

    return {
      proof,
      publicSignals,
      verificationKey: vKey,
      protocol: 'groth16',
      curve: 'bn128'
    };
  }

  /**
   * Generate main proof (full dataset with subset verification)
   */
  async generateMainProof({
    testResults,
    merkleRoot,
    aggregateScore,
    numTests,
    executionLogs,
    scoringCriteria,
    publicIndices,
    publicResults,
    subsetMerkleRoot,
    subsetAggregateScore
  }) {
    const circuitInputs = this.prepareMainCircuitInputs({
      testResults,
      merkleRoot,
      aggregateScore,
      numTests,
      executionLogs,
      scoringCriteria,
      publicIndices,
      publicResults,
      subsetMerkleRoot,
      subsetAggregateScore
    });

    // Generate witness and proof for main circuit
    const { proof, publicSignals } = await snarkjs.groth16.fullProve(
      circuitInputs,
      this.wasmPath,
      this.zkeyPath
    );

    // Load verification key
    const vKey = JSON.parse(
      await fs.promises.readFile(this.vkeyPath, 'utf8')
    );

    return {
      proof,
      publicSignals,
      verificationKey: vKey,
      protocol: 'groth16',
      curve: 'bn128',
      commitments: {
        logsCommitment: circuitInputs.logsHash.toString(),
        libraryVersion: circuitInputs.libraryCodeHash.toString(),
        scoringMethod: circuitInputs.scoringMethodHash.toString()
      }
    };
  }

  /**
   * Prepare subset circuit inputs
   */
  prepareSubsetCircuitInputs({
    publicResults,
    subsetMerkleRoot,
    subsetAggregateScore,
    numSubset
  }) {
    const intScores = this.prepareSubsetScores(publicResults, subsetAggregateScore, numSubset);
    const testSuiteHash = BigInt('0x' + subsetMerkleRoot);

    return {
      // Private inputs
      scores: intScores.map(s => BigInt(s)),
      numTestsPrivate: BigInt(numSubset),
      testSuiteHash: testSuiteHash,

      // Public inputs
      merkleRoot: testSuiteHash,
      claimedScore: BigInt(Math.round(subsetAggregateScore)),
      numTests: BigInt(numSubset)
    };
  }

  /**
   * Prepare main circuit inputs (with subset verification)
   */
  prepareMainCircuitInputs({
    testResults,
    merkleRoot,
    aggregateScore,
    numTests,
    executionLogs,
    scoringCriteria,
    publicIndices,
    publicResults,
    subsetMerkleRoot,
    subsetAggregateScore
  }) {
    // Prepare base inputs (scores)
    const intScores = this.prepareScores(testResults, aggregateScore, numTests);

    // Prepare subset scores (extract from full scores at public indices)
    const subsetScores = [];
    for (let i = 0; i < this.maxSubset; i++) {
      if (i < publicIndices.length) {
        const idx = publicIndices[i];
        subsetScores.push(intScores[idx]);
      } else {
        subsetScores.push(0);
      }
    }

    // Prepare subset indices (pad to maxSubset)
    const paddedIndices = [...publicIndices];
    while (paddedIndices.length < this.maxSubset) {
      paddedIndices.push(0);
    }

    // Compute commitments
    const logsHash = this.hashExecutionLogs(executionLogs);
    const libraryCodeHash = this.hashLibraryVersion();
    const scoringMethodHash = this.hashScoringCriteria(scoringCriteria);

    const testSuiteHash = BigInt('0x' + merkleRoot);
    const subsetTestSuiteHash = BigInt('0x' + subsetMerkleRoot);

    return {
      // Private inputs (full dataset)
      scores: intScores.map(s => BigInt(s)),
      numTestsPrivate: BigInt(numTests),
      testSuiteHash: testSuiteHash,
      logsHash: logsHash,
      libraryCodeHash: libraryCodeHash,
      scoringMethodHash: scoringMethodHash,

      // Private inputs (subset verification)
      subsetScores: subsetScores.map(s => BigInt(s)),
      subsetIndices: paddedIndices.map(i => BigInt(i)),
      numSubsetPrivate: BigInt(publicIndices.length),
      subsetMerkleRootPrivate: subsetTestSuiteHash,
      subsetClaimedScorePrivate: BigInt(Math.round(subsetAggregateScore)),

      // Public inputs (full dataset)
      merkleRoot: testSuiteHash,
      claimedScore: BigInt(Math.round(aggregateScore)),
      numTests: BigInt(numTests),

      // Public inputs (subset)
      subsetMerkleRoot: subsetTestSuiteHash,
      subsetClaimedScore: BigInt(Math.round(subsetAggregateScore)),
      numSubset: BigInt(publicIndices.length)
    };
  }

  /**
   * Prepare scores for subset (similar to prepareScores but for subset only)
   */
  prepareSubsetScores(publicResults, subsetAggregateScore, numSubset) {
    const intScores = [];

    for (let i = 0; i < publicResults.length && i < this.maxSubset; i++) {
      const result = publicResults[i];
      if (typeof result.score === 'boolean') {
        intScores.push(result.score ? 100 : 0);
      } else {
        let s = Math.round(Number(result.score));
        if (!Number.isFinite(s)) s = 0;
        if (s < 0) s = 0;
        if (s > 100) s = 100;
        intScores.push(s);
      }
    }

    // Pad to maxSubset
    while (intScores.length < this.maxSubset) intScores.push(0);

    // Adjust to match target sum exactly
    const claimed = Math.round(Number(subsetAggregateScore));
    const targetSum = claimed * numSubset;
    let currentSum = intScores.slice(0, numSubset).reduce((a, b) => a + b, 0);
    let delta = targetSum - currentSum;

    if (delta !== 0 && numSubset > 0) {
      for (let i = 0; i < numSubset && delta !== 0; i++) {
        if (delta > 0 && intScores[i] < 100) {
          intScores[i]++;
          delta--;
        } else if (delta < 0 && intScores[i] > 0) {
          intScores[i]--;
          delta++;
        }
      }
    }

    return intScores;
  }

  /**
   * Prepare enhanced circuit inputs with commitments
   */
  prepareEnhancedCircuitInputs({
    testResults,
    merkleRoot,
    aggregateScore,
    numTests,
    executionLogs,
    scoringCriteria
  }) {
    // Prepare base inputs (scores)
    const intScores = this.prepareScores(testResults, aggregateScore, numTests);

    // ✅ NEW: Compute logs commitment
    const logsHash = this.hashExecutionLogs(executionLogs);

    // ✅ NEW: Compute library version commitment
    const libraryCodeHash = this.hashLibraryVersion();

    // ✅ NEW: Compute scoring method commitment
    const scoringMethodHash = this.hashScoringCriteria(scoringCriteria);

    const testSuiteHash = BigInt('0x' + merkleRoot);

    return {
      // Private inputs
      scores: intScores.map(s => BigInt(s)),
      numTestsPrivate: BigInt(numTests),
      testSuiteHash: testSuiteHash,
      logsHash: logsHash,                     // NEW
      libraryCodeHash: libraryCodeHash,       // NEW
      scoringMethodHash: scoringMethodHash,   // NEW

      // Public inputs
      merkleRoot: testSuiteHash,
      claimedScore: BigInt(Math.round(aggregateScore)),
      numTests: BigInt(numTests)
    };
  }

  /**
   * Prepare integer scores that sum correctly
   */
  prepareScores(testResults, aggregateScore, numTests) {
    const intScores = [];

    for (let i = 0; i < testResults.length && i < this.maxTests; i++) {
      const result = testResults[i];
      if (typeof result.score === 'boolean') {
        intScores.push(result.score ? 100 : 0);
      } else {
        let s = Math.round(Number(result.score));
        if (!Number.isFinite(s)) s = 0;
        if (s < 0) s = 0;
        if (s > 100) s = 100;
        intScores.push(s);
      }
    }

    // Pad to maxTests
    while (intScores.length < this.maxTests) intScores.push(0);

    // Adjust to match target sum exactly
    const claimed = Math.round(Number(aggregateScore));
    const targetSum = claimed * numTests;
    let currentSum = intScores.slice(0, numTests).reduce((a, b) => a + b, 0);
    let delta = targetSum - currentSum;

    if (delta !== 0 && numTests > 0) {
      for (let i = 0; i < numTests && delta !== 0; i++) {
        if (delta > 0 && intScores[i] < 100) {
          intScores[i]++;
          delta--;
        } else if (delta < 0 && intScores[i] > 0) {
          intScores[i]--;
          delta++;
        }
      }
    }

    return intScores;
  }

  /**
   * ✅ NEW: Hash execution logs to create commitment
   * Anyone can later verify logs match this commitment
   */
  hashExecutionLogs(executionLogs) {
    if (!executionLogs || executionLogs.length === 0) {
      // Empty logs - return hash of empty array
      const emptyHash = crypto.createHash('sha256').update('[]').digest('hex');
      return BigInt('0x' + emptyHash);
    }

    // Create deterministic hash of all logs
    const logsString = JSON.stringify(executionLogs, Object.keys(executionLogs).sort());
    const hash = crypto.createHash('sha256').update(logsString).digest('hex');

    return BigInt('0x' + hash);
  }

  /**
   * ✅ NEW: Hash library version/code to prove which library was used
   */
  hashLibraryVersion() {
    // Option 1: Simple version string
    const versionString = `agent-verifier@${this.libraryVersion}`;
    const hash = crypto.createHash('sha256').update(versionString).digest('hex');

    // Option 2 (more secure): Could hash actual library source code
    // This would require reading and hashing all library files

    return BigInt('0x' + hash);
  }

  /**
   * ✅ NEW: Hash scoring criteria to prove evaluation method
   */
  hashScoringCriteria(scoringCriteria) {
    if (!scoringCriteria) {
      // Default criteria
      const defaultCriteria = 'semantic-similarity-ai-scored';
      const hash = crypto.createHash('sha256').update(defaultCriteria).digest('hex');
      return BigInt('0x' + hash);
    }

    // Hash the specific criteria
    const criteriaString = typeof scoringCriteria === 'string'
      ? scoringCriteria
      : JSON.stringify(scoringCriteria, Object.keys(scoringCriteria).sort());

    const hash = crypto.createHash('sha256').update(criteriaString).digest('hex');
    return BigInt('0x' + hash);
  }

  /**
   * Check if circuit files exist
   */
  checkSetup() {
    return {
      wasmExists: fs.existsSync(this.wasmPath),
      zkeyExists: fs.existsSync(this.zkeyPath),
      vkeyExists: fs.existsSync(this.vkeyPath)
    };
  }

  /**
   * Check if subset circuit files exist
   */
  checkSubsetSetup() {
    return {
      wasmExists: fs.existsSync(this.wasmPathSubset),
      zkeyExists: fs.existsSync(this.zkeyPathSubset),
      vkeyExists: fs.existsSync(this.vkeyPathSubset)
    };
  }

  /**
   * Generate placeholder proof with enhanced commitments
   */
  generatePlaceholderProof({
    merkleRoot,
    aggregateScore,
    numTests,
    executionLogs,
    scoringCriteria
  }) {
    // Compute commitments even for placeholder
    const logsHash = this.hashExecutionLogs(executionLogs);
    const libraryCodeHash = this.hashLibraryVersion();
    const scoringMethodHash = this.hashScoringCriteria(scoringCriteria);

    const testSuiteHash = BigInt('0x' + merkleRoot);

    return {
      proof: {
        pi_a: ['0', '0', '1'],
        pi_b: [['0', '0'], ['0', '0'], ['1', '0']],
        pi_c: ['0', '0', '1'],
        protocol: 'groth16',
        curve: 'bn128'
      },
      publicSignals: [
        testSuiteHash.toString(),
        Math.round(aggregateScore).toString(),
        numTests.toString()
      ],
      verificationKey: this.generatePlaceholderVKey(),
      protocol: 'groth16',
      curve: 'bn128',
      isPlaceholder: true,
      // ✅ Include commitments even in placeholder
      commitments: {
        logsCommitment: logsHash.toString(),
        libraryVersion: libraryCodeHash.toString(),
        scoringMethod: scoringMethodHash.toString()
      }
    };
  }

  /**
   * Generate placeholder verification key
   */
  generatePlaceholderVKey() {
    return {
      protocol: 'groth16',
      curve: 'bn128',
      nPublic: 3,
      vk_alpha_1: ['0', '0', '1'],
      vk_beta_2: [['0', '0'], ['0', '0'], ['1', '0']],
      vk_gamma_2: [['0', '0'], ['0', '0'], ['1', '0']],
      vk_delta_2: [['0', '0'], ['0', '0'], ['1', '0']],
      vk_alphabeta_12: [],
      IC: [['0', '0', '1'], ['0', '0', '1'], ['0', '0', '1'], ['0', '0', '1']]
    };
  }

  /**
   * Generate placeholder dual proof (when circuits not compiled)
   */
  generatePlaceholderDualProof({
    merkleRoot,
    aggregateScore,
    numTests,
    executionLogs,
    scoringCriteria,
    publicIndices,
    subsetMerkleRoot,
    subsetAggregateScore,
    publicResults
  }) {
    // Compute commitments
    const logsHash = this.hashExecutionLogs(executionLogs);
    const libraryCodeHash = this.hashLibraryVersion();
    const scoringMethodHash = this.hashScoringCriteria(scoringCriteria);

    const testSuiteHash = BigInt('0x' + merkleRoot);
    const subsetTestSuiteHash = BigInt('0x' + subsetMerkleRoot);

    // Generate placeholder main proof
    const mainProof = {
      proof: {
        pi_a: ['0', '0', '1'],
        pi_b: [['0', '0'], ['0', '0'], ['1', '0']],
        pi_c: ['0', '0', '1'],
        protocol: 'groth16',
        curve: 'bn128'
      },
      publicSignals: [
        testSuiteHash.toString(),
        Math.round(aggregateScore).toString(),
        numTests.toString(),
        subsetTestSuiteHash.toString(),
        Math.round(subsetAggregateScore).toString(),
        publicIndices.length.toString()
      ],
      verificationKey: this.generatePlaceholderVKey(),
      protocol: 'groth16',
      curve: 'bn128',
      commitments: {
        logsCommitment: logsHash.toString(),
        libraryVersion: libraryCodeHash.toString(),
        scoringMethod: scoringMethodHash.toString()
      }
    };

    // Generate placeholder subset proof
    const subsetProof = {
      proof: {
        pi_a: ['0', '0', '1'],
        pi_b: [['0', '0'], ['0', '0'], ['1', '0']],
        pi_c: ['0', '0', '1'],
        protocol: 'groth16',
        curve: 'bn128'
      },
      publicSignals: [
        subsetTestSuiteHash.toString(),
        Math.round(subsetAggregateScore).toString(),
        publicIndices.length.toString()
      ],
      verificationKey: this.generatePlaceholderVKey(),
      protocol: 'groth16',
      curve: 'bn128'
    };

    return {
      mainProof,
      subsetProof,
      isPlaceholder: true,
      protocol: 'groth16-dual',
      publicIndices,
      publicTests: publicResults.length
    };
  }
}
